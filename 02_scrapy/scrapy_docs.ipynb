{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968ee719-bf68-4e29-9408-ec844121f4c9",
   "metadata": {},
   "source": [
    "# SCRAPY [DOCUMENTATION](https://docs.scrapy.org/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be5cd1-1600-4414-a5de-aab700913727",
   "metadata": {},
   "source": [
    "Scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f46d7-496c-4360-b7a5-451108e6d521",
   "metadata": {},
   "source": [
    "# Basic commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dcc10f-fcb3-4ac9-8f77-872712283f6c",
   "metadata": {},
   "source": [
    "## Scrapy command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b22b9f-ec2a-4403-b3d9-806eeaa5c25c",
   "metadata": {},
   "source": [
    "|Scrapy command line|Description|\n",
    "|-|-|\n",
    "|`scrapy --help`|list all the available commands (run from the project's directory)|\n",
    "|**List info**||\n",
    "|`scrapy list`|list all available crawlers (run from the project's deirectory)|\n",
    "|**Crawl a random webpage in shell**||\n",
    "|`scrapy shell <url>`||\n",
    "|(inside shell) `view(response)`|open the resonse object in your browser|\n",
    "|**Maintain the project**||\n",
    "|`scrapy startproject project_name`|create a new project|\n",
    "|`scrapy crawl spider_name`|run the spider (from the project's top level dir)|\n",
    "|||\n",
    "|||\n",
    "|||\n",
    "|||\n",
    "\n",
    "```\n",
    "scrapy --help\n",
    "Scrapy 2.11.0 - active project: tutorial\n",
    "\n",
    "Usage:\n",
    "  scrapy <command> [options] [args]\n",
    "\n",
    "Available commands:\n",
    "  bench         Run quick benchmark test\n",
    "  check         Check spider contracts\n",
    "  crawl         Run a spider\n",
    "  edit          Edit spider\n",
    "  fetch         Fetch a URL using the Scrapy downloader\n",
    "  genspider     Generate new spider using pre-defined templates\n",
    "  list          List available spiders\n",
    "  parse         Parse URL (using its spider) and print the results\n",
    "  runspider     Run a self-contained spider (without creating a project)\n",
    "  settings      Get settings values\n",
    "  shell         Interactive scraping console\n",
    "  startproject  Create new project\n",
    "  version       Print Scrapy version\n",
    "  view          Open URL in browser, as seen by Scrapy\n",
    "\n",
    "Use \"scrapy <command> -h\" to see more info about a command\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d33a9d-eda2-4f44-b287-6512d7cef5ff",
   "metadata": {},
   "source": [
    "## Scrapy extraction most common tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e8530-49b4-4ec5-b347-b719697157af",
   "metadata": {},
   "source": [
    "|Scrapy extraction tools|Description|\n",
    "|-|-|\n",
    "|`view(response)`|open the response page from the shell in your web browser|\n",
    "|**Response status codes**||\n",
    "|`response.status`||\n",
    "|**CSS selectors**||\n",
    "|`response.css`||\n",
    "|`response.css(\"title::text\").getall()`|get only text from the SelectorList|\n",
    "|||\n",
    "|||\n",
    "|||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a9b8e5-892f-4d1b-afca-6833d7d5902c",
   "metadata": {},
   "source": [
    "# <b>1. Installation guide</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4663917-c7e7-433a-9950-e1b523450097",
   "metadata": {},
   "source": [
    "We strongly recommend that you install Scrapy in a dedicated virtualenv, to avoid conflicting with your system packages.\n",
    "\n",
    "```sh\n",
    "(venv) $ pip install Scrapy\n",
    "```\n",
    "\n",
    "Scrapy is written in pure Python and depends on a few key Python packages (among others):\n",
    "\n",
    "- lxml, an efficient XML and HTML parser\n",
    "- parsel, an HTML/XML data extraction library written on top of lxml,\n",
    "- w3lib, a multi-purpose helper for dealing with URLs and web page encodings\n",
    "- twisted, an asynchronous networking framework\n",
    "- cryptography and pyOpenSSL, to deal with various network-level security needs\n",
    "\n",
    "Some of these packages themselves depend on non-Python packages that might require additional installation steps depending on your platform. Please check [platform-specific guides](https://docs.scrapy.org/en/latest/intro/install.html#intro-install-platform-notes).\n",
    "\n",
    "In case of any trouble related to these dependencies, please refer to their respective installation instructions:\n",
    "\n",
    "- [lxml installation](https://lxml.de/installation.html)\n",
    "- [cryptography installation](https://cryptography.io/en/latest/installation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a0466-e563-49de-a9d1-b380ced0c1f9",
   "metadata": {},
   "source": [
    "# <b>2. Scrapy tutorial</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1eb925-6bb2-4b85-8261-56c0b924f4b6",
   "metadata": {},
   "source": [
    "This tutorial will walk you through these tasks:\n",
    "\n",
    "- Creating a new Scrapy project\n",
    "- Writing a spider to crawl a site and extract data\n",
    "- Exporting the scraped data using the command line\n",
    "- Changing spider to recursively follow links\n",
    "- Using spider arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d7112-8b38-4950-a190-6272f74f6903",
   "metadata": {},
   "source": [
    "# 2.1 Creating a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312e67a-4e29-47dd-9799-01db5661b765",
   "metadata": {},
   "source": [
    "Before you start scraping, you will have to set up a new Scrapy project. Enter a directory where you’d like to store your code and run:\n",
    "\n",
    "```sh\n",
    "scrapy startproject tutorial\n",
    "```\n",
    "```\n",
    "New Scrapy project 'tutorial', using template directory '/home/commi/venv/venv3.11/lib/python3.11/site-packages/scrapy/templates/project', created in:\n",
    "    /home/commi/Yandex.Disk/it_learning/08_web_scraping/02_scrapy/data/tutorial\n",
    "\n",
    "You can start your first spider with:\n",
    "    cd tutorial\n",
    "    scrapy genspider example example.com\n",
    "```\n",
    "\n",
    "This will create a `tutorial` directory with the following contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e616c4-6e21-4f23-8aef-6a47dd54ed32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T20:41:14.321005Z",
     "iopub.status.busy": "2024-02-04T20:41:14.320026Z",
     "iopub.status.idle": "2024-02-04T20:41:14.486706Z",
     "shell.execute_reply": "2024-02-04T20:41:14.484683Z",
     "shell.execute_reply.started": "2024-02-04T20:41:14.320929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtutorial\u001b[0m\n",
      "├── scrapy.cfg\n",
      "└── \u001b[01;34mtutorial\u001b[0m\n",
      "    ├── __init__.py\n",
      "    ├── items.py\n",
      "    ├── middlewares.py\n",
      "    ├── pipelines.py\n",
      "    ├── settings.py\n",
      "    └── \u001b[01;34mspiders\u001b[0m\n",
      "        └── __init__.py\n",
      "\n",
      "3 directories, 7 files\n"
     ]
    }
   ],
   "source": [
    "cd ./data\n",
    "tree tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f47d0d-42a0-45d1-81bc-19405b2282cd",
   "metadata": {},
   "source": [
    "```\n",
    "tutorial/\n",
    "    scrapy.cfg            # deploy configuration file\n",
    "\n",
    "    tutorial/             # project's Python module, you'll import your code from here\n",
    "        __init__.py\n",
    "\n",
    "        items.py          # project items definition file\n",
    "\n",
    "        middlewares.py    # project middlewares file\n",
    "\n",
    "        pipelines.py      # project pipelines file\n",
    "\n",
    "        settings.py       # project settings file\n",
    "\n",
    "        spiders/          # a directory where you'll later put your spiders\n",
    "            __init__.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fa774-eea7-4e39-992d-743fb81519f4",
   "metadata": {},
   "source": [
    "# 2.2 Our first Spider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932bf53-e3c9-4209-9533-3590627dd4b7",
   "metadata": {},
   "source": [
    "**Spiders** are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass `Spider` and define the initial requests to make, optionally \n",
    "- how to follow links in the pages, and \n",
    "- how to parse the downloaded page content to extract data.\n",
    "\n",
    "This is the code for our first `Spider`. Save it in a file named `quotes_spider.py` under the `tutorial/spiders` directory in your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31f0595-b402-48ee-8f1b-fbffacb2d778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T20:43:53.627476Z",
     "iopub.status.busy": "2024-02-04T20:43:53.625433Z",
     "iopub.status.idle": "2024-02-04T20:43:53.742875Z",
     "shell.execute_reply": "2024-02-04T20:43:53.741806Z",
     "shell.execute_reply.started": "2024-02-04T20:43:53.627403Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:\n",
      "draft.py  \u001b[0m\u001b[01;34m__pycache__\u001b[0m  quotes.jsonl  quotes_spider.py  \u001b[01;34mtutorial\u001b[0m\n",
      "\n",
      "./__pycache__:\n",
      "draft.cpython-311.pyc\n",
      "\n",
      "./tutorial:\n",
      "scrapy.cfg  \u001b[01;34mtutorial\u001b[0m\n",
      "\n",
      "./tutorial/tutorial:\n",
      "__init__.py  items.py  middlewares.py  pipelines.py  settings.py  \u001b[01;34mspiders\u001b[0m\n",
      "\n",
      "./tutorial/tutorial/spiders:\n",
      "__init__.py\n"
     ]
    }
   ],
   "source": [
    "ls -R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd6194-8510-423d-b568-2aedbd634900",
   "metadata": {},
   "source": [
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            \"https://quotes.toscrape.com/page/1/\",\n",
    "            \"https://quotes.toscrape.com/page/2/\",\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f\"quotes-{page}.html\"\n",
    "        Path(filename).write_bytes(response.body)\n",
    "        self.log(f\"Saved file {filename}\")\n",
    "```\n",
    "\n",
    "As you can see, our Spider subclasses `scrapy.Spider` and defines some attributes and methods:\n",
    "\n",
    "- `name`: identifies the Spider. It **must be unique within a project**, that is, you can’t set the same name for different Spiders.\n",
    "\n",
    "- `start_requests()`: must return an iterable of `Request`s (you can return a **list** of requests or write a **generator** function) which the Spider will begin to crawl from. Subsequent requests will be generated successively from these initial requests.\n",
    "\n",
    "- `parse()`: a method that will be called to handle the response downloaded for each of the requests made. The `response` parameter is an instance of `TextResponse` that holds the page content and has further helpful methods to handle it.\n",
    "\n",
    "The `parse()` method usually parses the `response`, extracting the scraped data as dicts and also finding new URLs to follow and creating new requests (`Request`) from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f33ea-00e0-464f-a5c2-35378c70e7af",
   "metadata": {},
   "source": [
    "## How to run our spider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b388f81-c947-4fea-95f8-4a94758c5fd1",
   "metadata": {},
   "source": [
    "To put our spider to work, go to the project’s top level directory and run:\n",
    "\n",
    "```sh\n",
    "scrapy crawl quotes\n",
    "```\n",
    "This command runs the spider with name `quotes` that we’ve just added, that will send some requests for the `quotes.toscrape.com` domain. You will get an output similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e7e96b-75f6-4259-9664-5ddc3d3c8bc6",
   "metadata": {},
   "source": [
    "```\n",
    "2024-02-05 01:57:09 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: tutorial)\n",
    "2024-02-05 01:57:09 [scrapy.utils.log] INFO: Versions: lxml 5.1.0.0, libxml2 2.12.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0], pyOpenSSL 24.0.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.2, Platform Linux-6.1.0-17-amd64-x86_64-with-glibc2.36\n",
    "2024-02-05 01:57:09 [scrapy.addons] INFO: Enabled addons:\n",
    "[]\n",
    "2024-02-05 01:57:09 [asyncio] DEBUG: Using selector: EpollSelector\n",
    "2024-02-05 01:57:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
    "2024-02-05 01:57:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
    "2024-02-05 01:57:09 [scrapy.extensions.telnet] INFO: Telnet Password: b9a7a03404bf04d7\n",
    "2024-02-05 01:57:09 [scrapy.middleware] INFO: Enabled extensions:\n",
    "['scrapy.extensions.corestats.CoreStats',\n",
    " 'scrapy.extensions.telnet.TelnetConsole',\n",
    " 'scrapy.extensions.memusage.MemoryUsage',\n",
    " 'scrapy.extensions.logstats.LogStats']\n",
    "2024-02-05 01:57:09 [scrapy.crawler] INFO: Overridden settings:\n",
    "{'BOT_NAME': 'tutorial',\n",
    " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
    " 'NEWSPIDER_MODULE': 'tutorial.spiders',\n",
    " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
    " 'ROBOTSTXT_OBEY': True,\n",
    " 'SPIDER_MODULES': ['tutorial.spiders'],\n",
    " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
    "2024-02-05 01:57:09 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
    "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
    " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
    " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
    " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
    " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
    " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
    " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
    " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
    " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
    "2024-02-05 01:57:09 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
    "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
    " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
    " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
    " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
    " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
    "2024-02-05 01:57:09 [scrapy.middleware] INFO: Enabled item pipelines:\n",
    "[]\n",
    "2024-02-05 01:57:09 [scrapy.core.engine] INFO: Spider opened\n",
    "2024-02-05 01:57:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
    "2024-02-05 01:57:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
    "2024-02-05 01:57:09 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n",
    "2024-02-05 01:57:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n",
    "2024-02-05 01:57:10 [quotes] DEBUG: Saved file quotes-1.html\n",
    "2024-02-05 01:57:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)\n",
    "2024-02-05 01:57:10 [quotes] DEBUG: Saved file quotes-2.html\n",
    "2024-02-05 01:57:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
    "2024-02-05 01:57:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
    "{'downloader/request_bytes': 684,\n",
    " 'downloader/request_count': 3,\n",
    " 'downloader/request_method_count/GET': 3,\n",
    " 'downloader/response_bytes': 25556,\n",
    " 'downloader/response_count': 3,\n",
    " 'downloader/response_status_count/200': 2,\n",
    " 'downloader/response_status_count/404': 1,\n",
    " 'elapsed_time_seconds': 1.235283,\n",
    " 'finish_reason': 'finished',\n",
    " 'finish_time': datetime.datetime(2024, 2, 4, 20, 57, 10, 482312, tzinfo=datetime.timezone.utc),\n",
    " 'log_count/DEBUG': 8,\n",
    " 'log_count/INFO': 10,\n",
    " 'memusage/max': 65585152,\n",
    " 'memusage/startup': 65585152,\n",
    " 'response_received_count': 3,\n",
    " 'robotstxt/request_count': 1,\n",
    " 'robotstxt/response_count': 1,\n",
    " 'robotstxt/response_status_count/404': 1,\n",
    " 'scheduler/dequeued': 2,\n",
    " 'scheduler/dequeued/memory': 2,\n",
    " 'scheduler/enqueued': 2,\n",
    " 'scheduler/enqueued/memory': 2,\n",
    " 'start_time': datetime.datetime(2024, 2, 4, 20, 57, 9, 247029, tzinfo=datetime.timezone.utc)}\n",
    "2024-02-05 01:57:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498b6dc-d419-43a6-975f-c2fe9809be7a",
   "metadata": {},
   "source": [
    "Now, check the files in the current directory. You should notice that two new files have been created: \n",
    "- quotes-1.html and \n",
    "- quotes-2.html, \n",
    "\n",
    "with the content for the respective URLs, as our parse method instructs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "898572ae-7c3c-4152-9ec0-c516d00087ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:18:03.312774Z",
     "iopub.status.busy": "2024-02-04T22:18:03.312022Z",
     "iopub.status.idle": "2024-02-04T22:18:03.422712Z",
     "shell.execute_reply": "2024-02-04T22:18:03.421645Z",
     "shell.execute_reply.started": "2024-02-04T22:18:03.312747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quotes-1.html  quotes-2.html  scrapy.cfg  \u001b[0m\u001b[01;34mtutorial\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls ./tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a184ab66-4896-47d7-9c7e-1643e6ca04b5",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-02-04T22:18:41.703321Z",
     "iopub.status.busy": "2024-02-04T22:18:41.702513Z",
     "iopub.status.idle": "2024-02-04T22:18:41.914813Z",
     "shell.execute_reply": "2024-02-04T22:18:41.913439Z",
     "shell.execute_reply.started": "2024-02-04T22:18:41.703251Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Quotes to Scrape</title>\n",
      "    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/main.css\">\n",
      "</head>\n",
      "<body>\n",
      "    <div class=\"container\">\n",
      "        <div class=\"row header-box\">\n",
      "            <div class=\"col-md-8\">\n",
      "                <h1>\n",
      "                    <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
      "                </h1>\n",
      "            </div>\n",
      "            <div class=\"col-md-4\">\n",
      "                <p>\n",
      "                \n",
      "                    <a href=\"/login\">Login</a>\n",
      "                \n",
      "                </p>\n",
      "            </div>\n",
      "        </div>\n",
      "    \n",
      "\n",
      "<div class=\"row\">\n",
      "    <div class=\"col-md-8\">\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
      "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"change,deep-thoughts,thinking,world\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show what we truly are, far more than our abilities.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\n",
      "        <a href=\"/author/J-K-Rowling\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"abilities,choices\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
      "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"inspirational,life,live,miracle,miracles\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/live/page/1/\">live</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/miracle/page/1/\">miracle</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/miracles/page/1/\">miracles</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">Jane Austen</small>\n",
      "        <a href=\"/author/Jane-Austen\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"aliteracy,books,classic,humor\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/aliteracy/page/1/\">aliteracy</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/books/page/1/\">books</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/classic/page/1/\">classic</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“Imperfection is beauty, madness is genius and it&#39;s better to be absolutely ridiculous than absolutely boring.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">Marilyn Monroe</small>\n",
      "        <a href=\"/author/Marilyn-Monroe\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"be-yourself,inspirational\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/be-yourself/page/1/\">be-yourself</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“Try not to become a man of success. Rather become a man of value.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
      "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"adulthood,success,value\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/adulthood/page/1/\">adulthood</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/success/page/1/\">success</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/value/page/1/\">value</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“It is better to be hated for what you are than to be loved for what you are not.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">André Gide</small>\n",
      "        <a href=\"/author/Andre-Gide\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"life,love\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/love/page/1/\">love</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“I have not failed. I&#39;ve just found 10,000 ways that won&#39;t work.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">Thomas A. Edison</small>\n",
      "        <a href=\"/author/Thomas-A-Edison\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"edison,failure,inspirational,paraphrased\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/edison/page/1/\">edison</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/failure/page/1/\">failure</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/paraphrased/page/1/\">paraphrased</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“A woman is like a tea bag; you never know how strong it is until it&#39;s in hot water.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">Eleanor Roosevelt</small>\n",
      "        <a href=\"/author/Eleanor-Roosevelt\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"misattributed-eleanor-roosevelt\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/misattributed-eleanor-roosevelt/page/1/\">misattributed-eleanor-roosevelt</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“A day without sunshine is like, you know, night.”</span>\n",
      "        <span>by <small class=\"author\" itemprop=\"author\">Steve Martin</small>\n",
      "        <a href=\"/author/Steve-Martin\">(about)</a>\n",
      "        </span>\n",
      "        <div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"humor,obvious,simile\" /    > \n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/obvious/page/1/\">obvious</a>\n",
      "            \n",
      "            <a class=\"tag\" href=\"/tag/simile/page/1/\">simile</a>\n",
      "            \n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <nav>\n",
      "        <ul class=\"pager\">\n",
      "            \n",
      "            \n",
      "            <li class=\"next\">\n",
      "                <a href=\"/page/2/\">Next <span aria-hidden=\"true\">&rarr;</span></a>\n",
      "            </li>\n",
      "            \n",
      "        </ul>\n",
      "    </nav>\n",
      "    </div>\n",
      "    <div class=\"col-md-4 tags-box\">\n",
      "        \n",
      "            <h2>Top Ten tags</h2>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 28px\" href=\"/tag/love/\">love</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 26px\" href=\"/tag/inspirational/\">inspirational</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 26px\" href=\"/tag/life/\">life</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 24px\" href=\"/tag/humor/\">humor</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 22px\" href=\"/tag/books/\">books</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 14px\" href=\"/tag/reading/\">reading</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 10px\" href=\"/tag/friendship/\">friendship</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 8px\" href=\"/tag/friends/\">friends</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 8px\" href=\"/tag/truth/\">truth</a>\n",
      "            </span>\n",
      "            \n",
      "            <span class=\"tag-item\">\n",
      "            <a class=\"tag\" style=\"font-size: 6px\" href=\"/tag/simile/\">simile</a>\n",
      "            </span>\n",
      "            \n",
      "        \n",
      "    </div>\n",
      "</div>\n",
      "\n",
      "    </div>\n",
      "    <footer class=\"footer\">\n",
      "        <div class=\"container\">\n",
      "            <p class=\"text-muted\">\n",
      "                Quotes by: <a href=\"https://www.goodreads.com/quotes\">GoodReads.com</a>\n",
      "            </p>\n",
      "            <p class=\"copyright\">\n",
      "                Made with <span class='zyte'>❤</span> by <a class='zyte' href=\"https://www.zyte.com\">Zyte</a>\n",
      "            </p>\n",
      "        </div>\n",
      "    </footer>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "cat ./tutorial/quotes-1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc12bb0-3ad8-475c-8c62-f34a35fd7775",
   "metadata": {},
   "source": [
    "## What just happened under the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf9bea-4482-499c-b60a-8e16f745f855",
   "metadata": {},
   "source": [
    "Scrapy schedules the `scrapy.Request` objects returned by the `start_requests` method of the Spider. Upon receiving a `response` for each one, it instantiates `Response` objects and calls the callback method associated with the `request` (in this case, the `parse` method) passing the response as argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1817e5-2ae7-4871-84e6-bdceceb6cad1",
   "metadata": {},
   "source": [
    "## A shortcut to the `start_requests` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d87e87-96ac-4dda-8585-daf4d42c0839",
   "metadata": {},
   "source": [
    "Instead of implementing a `start_requests()` method that generates `scrapy.Request` objects from URLs, you can just define a `start_urls` class attribute with a list of URLs. This list will then be used by the default implementation of `start_requests()` to create the initial requests for your spider.\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "        \"https://quotes.toscrape.com/page/2/\",\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f\"quotes-{page}.html\"\n",
    "        Path(filename).write_bytes(response.body)\n",
    "        self.log(f\"Saved file {filename}\")\n",
    "```\n",
    "\n",
    "The `parse()` method will be called to handle each of the requests for those URLs, even though we haven’t explicitly told Scrapy to do so. This happens because `parse()` is Scrapy’s default callback method, which is called for requests without an explicitly assigned callback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7cb801-1c53-4875-8d28-06c6864a880d",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5074321-f17a-4daf-bdb7-9d4e84341021",
   "metadata": {},
   "source": [
    "The best way to learn how to extract data with Scrapy is trying **selectors** using the Scrapy shell. Run:\n",
    "\n",
    "> Note: Remember to always enclose urls in quotes when running Scrapy shell from command-line, otherwise urls containing arguments (i.e. & character) will not work.<br>\n",
    "</br>\n",
    "On Windows, use double quotes instead:<br>\n",
    "</br>\n",
    "`scrapy shell \"https://quotes.toscrape.com/page/1/\"`\n",
    "\n",
    "```sh\n",
    "scrapy shell 'https://quotes.toscrape.com/page/1/'\n",
    "```\n",
    "```\n",
    "2024-02-06 14:47:14 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: tutorial)\n",
    "2024-02-06 14:47:14 [scrapy.utils.log] INFO: Versions: lxml 5.1.0.0, libxml2 2.12.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0], pyOpenSSL 24.0.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.2, Platform Linux-6.1.0-17-amd64-x86_64-with-glibc2.36\n",
    "2024-02-06 14:47:14 [scrapy.addons] INFO: Enabled addons:\n",
    "[]\n",
    "2024-02-06 14:47:14 [asyncio] DEBUG: Using selector: EpollSelector\n",
    "2024-02-06 14:47:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
    "2024-02-06 14:47:14 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
    "2024-02-06 14:47:14 [scrapy.extensions.telnet] INFO: Telnet Password: 53d4e3939b5fb7e7\n",
    "2024-02-06 14:47:14 [scrapy.middleware] INFO: Enabled extensions:\n",
    "['scrapy.extensions.corestats.CoreStats',\n",
    " 'scrapy.extensions.telnet.TelnetConsole',\n",
    " 'scrapy.extensions.memusage.MemoryUsage']\n",
    "2024-02-06 14:47:14 [scrapy.crawler] INFO: Overridden settings:\n",
    "{'BOT_NAME': 'tutorial',\n",
    " 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
    " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
    " 'LOGSTATS_INTERVAL': 0,\n",
    " 'NEWSPIDER_MODULE': 'tutorial.spiders',\n",
    " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
    " 'ROBOTSTXT_OBEY': True,\n",
    " 'SPIDER_MODULES': ['tutorial.spiders'],\n",
    " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
    "2024-02-06 14:47:14 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
    "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
    " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
    " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
    " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
    " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
    " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
    " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
    " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
    " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
    "2024-02-06 14:47:14 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
    "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
    " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
    " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
    " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
    " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
    "2024-02-06 14:47:14 [scrapy.middleware] INFO: Enabled item pipelines:\n",
    "[]\n",
    "2024-02-06 14:47:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
    "2024-02-06 14:47:14 [scrapy.core.engine] INFO: Spider opened\n",
    "2024-02-06 14:47:15 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n",
    "2024-02-06 14:47:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n",
    "[s] Available Scrapy objects:\n",
    "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
    "[s]   crawler    <scrapy.crawler.Crawler object at 0x7f5b3ece0cd0>\n",
    "[s]   item       {}\n",
    "[s]   request    <GET https://quotes.toscrape.com/page/1/>\n",
    "[s]   response   <200 https://quotes.toscrape.com/page/1/>\n",
    "[s]   settings   <scrapy.settings.Settings object at 0x7f5b3ffddc10>\n",
    "[s]   spider     <DefaultSpider 'default' at 0x7f5b3e7fa950>\n",
    "[s] Useful shortcuts:\n",
    "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
    "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
    "[s]   shelp()           Shell help (print this help)\n",
    "[s]   view(response)    View response in a browser\n",
    "2024-02-06 14:47:16 [asyncio] DEBUG: Using selector: EpollSelector\n",
    "```\n",
    "```ipython\n",
    "In [1]: \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724096bd-8857-43c4-914f-5f51b35222d9",
   "metadata": {},
   "source": [
    "Using the shell, you can try selecting elements using [CSS](https://www.w3.org/TR/selectors) with the `response` object:\n",
    "\n",
    "```ipython\n",
    "In [1]: response.css(\"title\")\n",
    "Out[1]: [<Selector query='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]\n",
    "\n",
    "In [2]: response.status\n",
    "Out[2]: 200\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b34527-4301-4b70-be21-f50099b57f90",
   "metadata": {},
   "source": [
    "### `get_all()` and `get()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86093451-8b67-4636-98ed-91283d3236a6",
   "metadata": {},
   "source": [
    "The result of running `response.css('title')` is a list-like object called **SelectorList**, which represents a list of Selector objects that wrap around XML/HTML elements and allow you to run further queries to fine-grain the selection or extract the data.\n",
    "\n",
    "To extract the text from the title above, you can do:\n",
    "\n",
    "```ipython\n",
    "In [9]: response.css(\"title::text\").getall()\n",
    "Out[9]: ['Quotes to Scrape']\n",
    "```\n",
    "\n",
    "There are two things to note here: one is that we’ve added `::text` to the CSS query, to mean we want to select only the text elements directly inside `<title>` element. If we don’t specify `::text`, we’d get the full title element, including its tags:\n",
    "\n",
    "```ipython\n",
    "In [11]: response.css(\"title\").getall()\n",
    "Out[11]: ['<title>Quotes to Scrape</title>']\n",
    "```\n",
    "\n",
    "The other thing is that the result of calling `.getall()` is a _list_: it is possible that a selector returns more than one result, so we extract them all. When you know you just want the first result, as in this case, you can do:\n",
    "\n",
    "```ipython\n",
    "In [12]: response.css(\"title::text\").get()\n",
    "Out[12]: 'Quotes to Scrape'\n",
    "```\n",
    "\n",
    "As an alternative, you could’ve written:\n",
    "\n",
    "```ipython\n",
    "In [16]: response.css(\"title::text\")[0].get()\n",
    "Out[16]: 'Quotes to Scrape'\n",
    "```\n",
    "\n",
    "Accessing an index on a SelectorList instance will raise an `IndexError` exception if there are no results. You might want to use `.get()` directly on the SelectorList instance instead, which returns `None` if there are no results:\n",
    "\n",
    "```ipython\n",
    "In [17]: response.css(\"noelement\").get()\n",
    "In [18]: response.css(\"noelement\")[0].get()\n",
    "---------------------------------------------------------------------------\n",
    "IndexError                                Traceback (most recent call last)\n",
    "...\n",
    "IndexError: list index out of range\n",
    "```\n",
    "\n",
    "There’s a lesson here: for most scraping code, you want it to be resilient to errors due to things not being found on a page, so that even if some parts fail to be scraped, you can at least get some data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e7840-8d39-445e-8504-060085130009",
   "metadata": {},
   "source": [
    "### `re()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7055b91-e2f2-431e-9d30-c3b36a2750f8",
   "metadata": {},
   "source": [
    "Besides the `getall()` and `get()` methods, you can also use the `re()` method to extract using [regular expressions](https://docs.python.org/3/library/re.html):\n",
    "\n",
    "```ipython\n",
    "In [20]: response.css(\"title::text\").re(r\".*uot.*\")\n",
    "Out[20]: ['Quotes to Scrape']\n",
    "\n",
    "In [21]: response.css(\"title::text\").re(r\"Q\\w+\")\n",
    "Out[21]: ['Quotes']\n",
    "\n",
    "In [22]: response.css(\"title::text\").re(r\"(\\w+) to (\\w+)\")\n",
    "Out[22]: ['Quotes', 'Scrape']\n",
    "```\n",
    "\n",
    "- `\\w` represents any alphanumeric character (equivalent to `[a-zA-Z0-9_]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dadabc-6323-4054-9a69-20753f17d10a",
   "metadata": {},
   "source": [
    "### `view(response)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de88dc81-81b3-4be4-b122-93cb530599a3",
   "metadata": {},
   "source": [
    "In order to find the proper CSS selectors to use, you might find it useful to open the `response` page from the shell in your web browser using `view(response)`. You can use your browser’s developer tools to inspect the HTML and come up with a selector (see [Using your browser’s Developer Tools for scraping](https://docs.scrapy.org/en/latest/topics/developer-tools.html#topics-developer-tools)).\n",
    "\n",
    "[Selector Gadget](https://selectorgadget.com/) is also a nice tool to quickly find CSS selector for visually selected elements, which works in many browsers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3677014c-d779-438a-b57d-dee723631675",
   "metadata": {},
   "source": [
    "### `XPath`: a brief intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74464531-cb38-4b0f-9444-3c2533fbf37f",
   "metadata": {},
   "source": [
    "See [XPath](../XPath_tutorial.ipynb#XPath).\n",
    "\n",
    "Besides CSS, Scrapy selectors also support using XPath expressions:\n",
    "\n",
    "```ipython\n",
    "In [24]: response.xpath(\"//title\")\n",
    "Out[24]: [<Selector query='//title' data='<title>Quotes to Scrape</title>'>]\n",
    "\n",
    "In [25]: response.xpath(\"//title/text()\").get()\n",
    "Out[25]: 'Quotes to Scrape'\n",
    "```\n",
    "\n",
    "XPath expressions are very powerful, and are the foundation of Scrapy Selectors. In fact, CSS selectors are converted to XPath under-the-hood. [You can see that](#Extracting-data) if you read closely the text representation of the selector objects in the shell.\n",
    "\n",
    "While perhaps not as popular as CSS selectors, XPath expressions offer more power because besides navigating the structure, it can also look at the content. Using XPath, you’re able to select things like: _select the link that contains the text “Next Page”_. This makes XPath very fitting to the task of scraping, and we encourage you to learn XPath even if you already know how to construct CSS selectors, it will make scraping much easier.\n",
    "\n",
    "We won’t cover much of XPath here, but you can read more about using [XPath with Scrapy Selectors](https://docs.scrapy.org/en/latest/topics/selectors.html#topics-selectors). To learn more about XPath, we recommend this [tutorial to learn XPath through examples](http://zvon.org/comp/r/tut-XPath_1.html), and this tutorial to learn [“how to think in XPath”](http://plasmasturm.org/log/xpath101/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe8ac6-9ebe-4464-b0a9-7b0dea6e4569",
   "metadata": {},
   "source": [
    "### Extracting quotes and authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b167e-98de-4068-9c34-61ecdb081034",
   "metadata": {},
   "source": [
    "Now that you know a bit about selection and extraction, let’s complete our spider by writing the code to extract the quotes from the web page.\n",
    "\n",
    "Each quote in `https://quotes.toscrape.com` is represented by HTML elements that look like this:\n",
    "\n",
    "```html\n",
    "<div class=\"quote\">\n",
    "    <span class=\"text\">“The world as we have created it is a process of our\n",
    "    thinking. It cannot be changed without changing our thinking.”</span>\n",
    "    <span>\n",
    "        by <small class=\"author\">Albert Einstein</small>\n",
    "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
    "    </span>\n",
    "    <div class=\"tags\">\n",
    "        Tags:\n",
    "        <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
    "        <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
    "        <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
    "        <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
    "    </div>\n",
    "</div>\n",
    "```\n",
    "\n",
    "Let’s open up `scrapy shell` and play a bit to find out how to extract the data we want. We get a list of selectors for the quote HTML elements with:\n",
    "\n",
    "```sh\n",
    "scrapy shell 'https://quotes.toscrape.com'\n",
    "```\n",
    "```ipython\n",
    "In [1]: response.css(\"div.quote\")\n",
    "Out[1]: \n",
    "[<Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
    " <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>]\n",
    "```\n",
    "\n",
    "Each of the selectors returned by the query above allows us to run further queries over their sub-elements. Let’s assign the first selector to a variable, so that we can run our CSS selectors directly on a particular quote:\n",
    "\n",
    "```ipython\n",
    "In [3]: quote = response.css(\"div.quote\")[0]\n",
    "```\n",
    "\n",
    "Now, let’s extract `text`, `author` and the `tags` from that quote using the `quote` object we just created:\n",
    "\n",
    "```ipython\n",
    "In [4]: text = quote.css(\"span.text::text\").get()\n",
    "In [5]: text\n",
    "Out[5]: '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'\n",
    "```\n",
    "\n",
    "Given that the `tags` are a list of strings, we can use the `.getall()` method to get all of them:\n",
    "\n",
    "```ipython\n",
    "In [6]: tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "In [7]: tags\n",
    "Out[7]: ['change', 'deep-thoughts', 'thinking', 'world']\n",
    "```\n",
    "\n",
    "Having figured out how to extract each bit, we can now iterate over all the quotes elements and put them together into a Python dictionary:\n",
    "\n",
    "```ipython\n",
    "In [8]: for quote in response.css(\"div.quote\"):\n",
    "   ...:     text = quote.css(\"span.text::text\").get()\n",
    "   ...:     author = quote.css(\"small.author::text\").get()\n",
    "   ...:     tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "   ...:     print(dict(text=text, author=author, tags=tags))\n",
    "   ...: \n",
    "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
    "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
    "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
    "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
    "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
    "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
    "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'André Gide', 'tags': ['life', 'love']}\n",
    "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
    "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
    "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc322623-939f-49b5-940d-ab90693866c1",
   "metadata": {},
   "source": [
    "### Extracting data in our spider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eaf8d7-9f0e-4a5e-b4a0-5491acdf0a4e",
   "metadata": {},
   "source": [
    "Let’s get back to our spider. Until now, it doesn’t extract any data in particular, just saves the whole HTML page to a local file. Let’s integrate the extraction logic above into our spider.\n",
    "\n",
    "A Scrapy spider typically generates many dictionaries containing the data extracted from the page. To do that, we use the `yield` Python keyword in the `callback`, as you can see below:\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "        \"https://quotes.toscrape.com/page/2/\",\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"small.author::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall(),\n",
    "            }\n",
    "```\n",
    "\n",
    "To run this spider, exit the `scrapy shell` and run the crawler:\n",
    "\n",
    "```sh\n",
    "quit()\n",
    "scrapy crawl quotes\n",
    "```\n",
    "```\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'André Gide', 'tags': ['life', 'love']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
    "2024-02-06 23:53:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n",
    "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}\n",
    "2024-02-06 23:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': \"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\", 'author': 'Marilyn Monroe', 'tags': ['friends', 'heartbreak', 'inspirational', 'life', 'love', 'sisters']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”', 'author': 'J.K. Rowling', 'tags': ['courage', 'friends']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': \"“If you can't explain it to a six year old, you don't understand it yourself.”\", 'author': 'Albert Einstein', 'tags': ['simplicity', 'understand']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\", 'author': 'Bob Marley', 'tags': ['love']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”', 'author': 'Dr. Seuss', 'tags': ['fantasy']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”', 'author': 'Douglas Adams', 'tags': ['life', 'navigation']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\", 'author': 'Elie Wiesel', 'tags': ['activism', 'apathy', 'hate', 'indifference', 'inspirational', 'love', 'opposite', 'philosophy']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”', 'author': 'Friedrich Nietzsche', 'tags': ['friendship', 'lack-of-friendship', 'lack-of-love', 'love', 'marriage', 'unhappy-marriage']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': '“Good friends, good books, and a sleepy conscience: this is the ideal life.”', 'author': 'Mark Twain', 'tags': ['books', 'contentment', 'friends', 'friendship', 'life']}\n",
    "2024-02-06 23:53:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/2/>\n",
    "{'text': '“Life is what happens to us while we are making other plans.”', 'author': 'Allen Saunders', 'tags': ['fate', 'life', 'misattributed-john-lennon', 'planning', 'plans']}\n",
    "2024-02-06 23:53:53 [scrapy.core.engine] INFO: Closing spider (finished)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0468328-06de-44fa-a1ed-8cff4be03ee4",
   "metadata": {},
   "source": [
    "## Storing the scraped data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31e6f5-1a84-4e62-bbed-e2a0e860f768",
   "metadata": {},
   "source": [
    "The simplest way to store the scraped data is by using [Feed exports](#2.8-Feed-exports), with the following command:\n",
    "\n",
    "```sh\n",
    "scrapy crawl quotes -O quotes.json\n",
    "```\n",
    "\n",
    "That will generate a `quotes.json` file containing all scraped items, serialized in JSON.\n",
    "\n",
    "The `-O` command-line switch overwrites any existing file; use `-o` instead to append new content to any existing file. However, appending to a JSON file makes the file contents invalid JSON. When appending to a file, consider using a different serialization format, such as `JSON Lines`:\n",
    "\n",
    "```sh\n",
    "scrapy crawl quotes -o quotes.jsonl\n",
    "```\n",
    "\n",
    "The [JSON Lines format](http://jsonlines.org/) is useful because it’s stream-like, you can easily append new records to it. It doesn’t have the same problem of JSON when you run twice. Also, as each record is a separate line, you can process big files without having to fit everything in memory, there are tools like `JQ` to help do that at the command-line.\n",
    "\n",
    "In small projects (like the one in this tutorial), that should be enough. However, if you want to perform more complex things with the scraped items, you can write an [Item Pipeline](#2.7-Item-Pipeline). A placeholder file for Item Pipelines has been set up for you when the project is created, in `tutorial/pipelines.py`. Though you don’t need to implement any item pipelines if you just want to store the scraped items.\n",
    "\n",
    "```sh\n",
    "$ scrapy crawl -h\n",
    "```\n",
    "```\n",
    "Usage\n",
    "=====\n",
    "  scrapy crawl [options] <spider>\n",
    "\n",
    "Run a spider\n",
    "\n",
    "Options\n",
    "=======\n",
    "  -h, --help            show this help message and exit\n",
    "  -a NAME=VALUE         set spider argument (may be repeated)\n",
    "  -o FILE, --output FILE\n",
    "                        append scraped items to the end of FILE (use - for stdout), to define format set a colon at the end of the output\n",
    "                        URI (i.e. -o FILE:FORMAT)\n",
    "  -O FILE, --overwrite-output FILE\n",
    "                        dump scraped items into FILE, overwriting any existing file, to define format set a colon at the end of the\n",
    "                        output URI (i.e. -O FILE:FORMAT)\n",
    "  -t FORMAT, --output-format FORMAT\n",
    "                        format to use for dumping items\n",
    "\n",
    "Global Options\n",
    "--------------\n",
    "  --logfile FILE        log file. if omitted stderr will be used\n",
    "  -L LEVEL, --loglevel LEVEL\n",
    "                        log level (default: DEBUG)\n",
    "  --nolog               disable logging completely\n",
    "  --profile FILE        write python cProfile stats to FILE\n",
    "  --pidfile FILE        write process ID to FILE\n",
    "  -s NAME=VALUE, --set NAME=VALUE\n",
    "                        set/override setting (may be repeated)\n",
    "  --pdb                 enable pdb on failure\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edd287b-96a0-4af3-a5f5-95f69dc6e739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T19:19:42.039144Z",
     "iopub.status.busy": "2024-02-06T19:19:42.037500Z",
     "iopub.status.idle": "2024-02-06T19:19:42.052495Z",
     "shell.execute_reply": "2024-02-06T19:19:42.048680Z",
     "shell.execute_reply.started": "2024-02-06T19:19:42.039015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# man jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d7db66-c191-448e-9218-a196f8ff5fbe",
   "metadata": {},
   "source": [
    "## Following links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f35f7cb-a8f6-4334-9b0f-9051deb9ed3f",
   "metadata": {},
   "source": [
    "Let’s say, instead of just scraping the stuff from the first two pages from https://quotes.toscrape.com, you want quotes from all the pages in the website.\n",
    "\n",
    "Now that you know how to extract data from pages, let’s see how to follow links from them.\n",
    "\n",
    "First thing is to extract the link to the page we want to follow. Examining our page, we can see there is a link to the next page with the following markup:\n",
    "\n",
    "```html\n",
    "<ul class=\"pager\">\n",
    "    <li class=\"next\">\n",
    "        <a href=\"/page/2/\">Next <span aria-hidden=\"true\">&rarr;</span></a>\n",
    "    </li>\n",
    "</ul>\n",
    "```\n",
    "\n",
    "We can try extracting it in the shell:\n",
    "\n",
    "```ipython\n",
    "In [1]: response.css(\"li.next a\")\n",
    "Out[1]: [<Selector query=\"descendant-or-self::li[@class and contains(concat(' ', normalize-space(@class), ' '), ' next ')]/descendant-or-self::*/a\" data='<a href=\"/page/2/\">Next <span aria-hi...'>]\n",
    "\n",
    "In [2]: response.css(\"li.next a\").get()\n",
    "Out[2]: '<a href=\"/page/2/\">Next <span aria-hidden=\"true\">→</span></a>'\n",
    "```\n",
    "\n",
    "This gets the anchor element, but we want the attribute `href`. For that, Scrapy supports a CSS extension that lets you select the attribute contents, like this:\n",
    "\n",
    "```ipython\n",
    "In [3]: response.css(\"li.next a::attr(href)\").get()\n",
    "Out[3]: '/page/2/'\n",
    "```\n",
    "There is also an `attrib` property available (see [Selecting element attributes](#Selecting-element-attributes) for more):\n",
    "\n",
    "```ipython\n",
    "In [4]: response.css(\"li.next a\").attrib[\"href\"]\n",
    "Out[4]: '/page/2/'\n",
    "```\n",
    "\n",
    "Let’s see now our spider modified to recursively follow the link to the next page, extracting data from it:\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"small.author::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall(),\n",
    "            }\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)\n",
    "```\n",
    "\n",
    "Now, after extracting the data, the `parse()` method looks for the link to the next page, builds a full absolute URL using the `urljoin()` method (since the links can be relative) and `yield`s a new request to the next page, registering itself as callback to handle the data extraction for the next page and to keep the crawling going through all the pages.\n",
    "\n",
    "What you see here is Scrapy’s mechanism of following links: when you `yield` a `Request` in a callback method, Scrapy will schedule that request to be sent and register a callback method to be executed when that request finishes.\n",
    "\n",
    "Using this, you can build complex crawlers that follow links according to rules you define, and extract different kinds of data depending on the page it’s visiting.\n",
    "\n",
    "In our example, it creates a sort of loop, following all the links to the next page until it doesn’t find one – handy for crawling blogs, forums and other sites with **pagination**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfc124-ed0e-4829-aee8-0adb585de4b3",
   "metadata": {},
   "source": [
    "### A shortcut for creating Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1ec72-a2f2-48e9-a8e0-2a32a371c98d",
   "metadata": {},
   "source": [
    "As a shortcut for creating `Request` objects you can use `response.follow`:\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall(),\n",
    "            }\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, callback=self.parse)\n",
    "```\n",
    "\n",
    "Unlike `scrapy.Request`, `response.follow` supports relative URLs directly - no need to call `urljoin`. Note that `response.follow` just returns a `Request` instance; you still have to `yield` this `Request`.\n",
    "\n",
    "You can also pass a selector to `response.follow` instead of a string; this selector should extract necessary attributes:\n",
    "\n",
    "```python\n",
    "for href in response.css(\"ul.pager a::attr(href)\"):\n",
    "    yield response.follow(href, callback=self.parse)\n",
    "```\n",
    "\n",
    "For `<a>` elements there is a shortcut: `response.follow` uses their `href` attribute automatically. So the code can be shortened further:\n",
    "\n",
    "```python\n",
    "for a in response.css(\"ul.pager a\"):\n",
    "    yield response.follow(a, callback=self.parse)\n",
    "```\n",
    "\n",
    "To create multiple requests from an iterable, you can use `response.follow_all` instead:\n",
    "\n",
    "```python\n",
    "anchors = response.css(\"ul.pager a\")\n",
    "yield from response.follow_all(anchors, callback=self.parse)\n",
    "```\n",
    "\n",
    "or, shortening it further:\n",
    "\n",
    "```python\n",
    "yield from response.follow_all(css=\"ul.pager a\", callback=self.parse)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e5ad1-05c5-4636-98c9-8a016fae4ead",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1381d791-26f4-408d-a798-caa6c5727581",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8996794c-e8cc-4e04-89f9-09171926e47f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```ipython\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```ipython\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5826f-b3b2-46bf-a1b5-66e582f5a2f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3403ec69-8dc0-477b-a537-dcbfc65ddb7d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13699c8c-eef5-4d0d-b69e-b21121a3f027",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccdcd8fd-cb0b-433a-94eb-dde2110a71e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59982c10-d964-4b67-a8ef-d0bce3bcf3e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef9a7b16-ff7b-4a7a-87bc-493872d986f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2de68331-8575-46a7-80ac-1bb9209ffadc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34c5cca8-a1a2-404e-ac88-465d7e2cf032",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a412e680-c70b-4475-a015-77cf463f4210",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d934c5d1-d988-44a6-a098-4d464b48ba10",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dae79ac-8e03-4808-b21b-953cccc7604c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0df26283-b1e0-4c32-a63f-4068eca2b61f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95382b34-e63b-4128-875f-58025d31b1ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7483d94-dd54-4d57-b69a-c544748966e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cabc71e-3b16-43f4-9378-31ebf24c7423",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d62b426d-351d-4b66-bd83-2756d20cd4fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98e22cce-1833-4cd5-94e6-2b6779e08c28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3916f90-938e-46ff-9ee1-e7234170d10c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "786d98d1-5afe-4d31-95bf-11adadeefae7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac6c22b-d647-463f-911c-dd1002dea82f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63aa9b2a-05a5-48dd-9687-631d284ee89b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74868bf5-4ef7-4393-85ab-95aa09c8ecd3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe1f69a1-b92a-4af3-8eac-2629aac4b773",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7e69ee7-c8eb-453d-b1f5-264a1e774b6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcf6da4d-658f-4dd7-9eee-8388c652728a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3beebe8b-2989-44a9-951d-bd65ba7b213b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e1be145-8ba7-4d5e-b542-0b71e751a308",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3af245-fe3a-4afd-b4f8-56910d9e8600",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e424c8b4-6eed-4f60-96a0-176527666aae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ecc175-d810-40db-95ef-74b232804aa5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef544087-fab3-4a48-8d37-c3cbd350654b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ff04e31-08e2-4197-961d-01956c1bfe9b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41345ee0-0d5f-4475-8f78-8b738323b697",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9219cab-f0df-43aa-8d9f-3a7349203e42",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ea2d5a9-7f91-4dfc-8361-69fd531687e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d3134e5-aca4-4318-8886-d89ea0cbf7cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db030b54-3832-4abf-a179-8e32d1b6f1a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b3e434f-affd-44b2-97df-6e23d1b8e429",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4dd8cf4-6aa2-43da-96f5-796d6d3ce7a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5166f341-a2c3-4908-8c4e-6cd21666ab77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb6644fd-48b0-4163-8d53-9c489163c8a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d1fc8da-5441-4ed9-8024-a21b689d86b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "420964e1-adda-4fb5-80e4-1235aa786fe8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4fcbc08-360a-4175-80df-5aa77077e92e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b544105f-00cb-447a-b5d9-572daa77bd52",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69551ab3-df93-48aa-ac26-62678a77de5f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31975ab0-5faf-405d-aa96-eb605494ef1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc633fd5-8748-42f5-ba38-fee275a449f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94252e27-b73d-402e-ad52-6c9c5344753c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aab10234-2791-4f5e-900a-716537b85f95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19438049-6aa3-459f-a584-49d18647a3cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6fd8804-e127-492b-af70-9b22c45e8e0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6563f27e-3c34-4c9e-9e5e-34bb5df5bf50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfd825c7-9b1c-4540-830c-602f941d91b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "930dcd86-0fee-41a2-be0f-4da1063702a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51731616-4e81-4d00-b9fa-5fbac9c4a150",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80cd3238-a5b0-463b-a152-08a211e8480d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b28f065-a9c0-45df-a479-b17848528559",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42564b9d-c659-4300-a792-1d3d65fb8812",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81701c7f-fc3c-46b1-9fe9-aee2f3ac4d5a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63cf3b5c-b984-4a33-bc82-1c8637f44861",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "061ff4e1-7028-4f13-8eae-bd65d3665b3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a63bc5a2-4741-4127-9155-0cdff8d53ec1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c268c1b5-94e3-4139-ba63-7dbb0e2e5500",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20443d47-b6db-44d3-b8e7-b89cac712a7b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ad392d-b2ce-46da-be8a-7b9d29ffcb3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "852a1acd-4ac4-4640-ac4c-6e2e187e0f40",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50bffaed-c4a8-4c89-8851-2033abcd986a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7c988c3-27b8-4410-8755-f23c0c467e2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa29800b-f665-4664-9381-1723dc84c378",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26f48843-5336-4271-ba87-c55d772f5b6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a463b00-cdeb-4f55-8590-747c0be0e1a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "420940e5-d883-4c50-8074-bee9e5d0ff6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d99488-222b-4274-ba31-5266c5549fd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e52c093c-4e9f-473e-9a10-b9b58e165587",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af778b46-f140-4f75-a887-a718d9e0b6d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e8de63-3f8c-4c37-881b-109f459bf113",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6450eec1-b75c-4115-a0ca-5411463cf5b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd1abff5-6bd2-4c9c-b9e8-300e4d13627a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f185efe-b616-43a1-a5e6-b353428a8bb9",
   "metadata": {},
   "source": [
    "# <b>Basic concepts</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d30708-5834-46f4-bbe3-b2a5a6788833",
   "metadata": {},
   "source": [
    "# 2.3 Selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2efea-b857-4781-bf32-6605780aae57",
   "metadata": {},
   "source": [
    "## Selecting element attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b13653d-cb7b-49f0-a03c-ef2793afdb41",
   "metadata": {},
   "source": [
    "# 2.7 Item Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75551f7a-22a1-4fe1-9efa-e06e9f59fe86",
   "metadata": {},
   "source": [
    "# 2.8 Feed exports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64ab36-c300-4809-a7b6-f881b010d0b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d6fba9f-0132-48ff-96b5-85c77107a00b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
